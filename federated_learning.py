# -*- coding: utf-8 -*-
"""Federated_Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j5kPWrG1aO3DCke9AudI_UUZ0xU72PAM
"""

# Run as the FIRST cell AFTER A FACTORY RESET.

import os
import sys

# Clear /etc/environment
!sudo truncate -s 0 /etc/environment

# Set CUDA environment variables
os.environ['CUDA_HOME'] = '/usr/local/cuda'
os.environ['LD_LIBRARY_PATH'] = f"{os.environ['CUDA_HOME']}/lib64:/lib/x86_64-linux-gnu:{os.environ.get('LD_LIBRARY_PATH', '')}"
os.environ['PATH'] = f"{os.environ['CUDA_HOME']}/bin:{os.environ.get('PATH', '')}"

# Persist environment variables
with open('/etc/environment', 'w') as f:
    f.write('CUDA_HOME=/usr/local/cuda\n')
    f.write('LD_LIBRARY_PATH=/usr/local/cuda/lib64:/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH\n')
    f.write('PATH=/usr/local/cuda/bin:$PATH\n')

print("\n--- Starting Installation with tf-nightly 2.20.0.dev20250514 ---")

# Clear pip cache
!pip cache purge

# Uninstall conflicting packages
!pip uninstall -y tensorflow tf-nightlmmmy numpy scipy appfl protobuf ml-dtypes tensorflow-datasets matplotlib tensorflow-privacy tensorflow-compression tensorflow-text tensorflow_decision_forests nvidia-cuda-runtime-cu11 nvidia-cudnn-cu11 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 torch torchao torchaudio torchdata torchsummary torchtune torchvision

# Remove residual cuDNN libraries
!sudo rm -f /lib/x86_64-linux-gnu/libcudnn*.so*
!sudo ldconfig

# Install CUDA and cuDNN
!pip install --no-cache-dir nvidia-cuda-runtime-cu12==12.4.127 nvidia-cudnn-cu12==9.1.0.70

# Install tf-nightly
!pip install --no-cache-dir --no-deps --force-reinstall tf-nightly==2.20.0.dev20250514

# Install dependencies for appfl and federated learning
!pip install --no-cache-dir numpy==1.26.4 scipy==1.15.3 ml-dtypes>=0.3.1 protobuf==4.25.3 appfl==1.5.0 tensorflow-datasets==4.9.2 matplotlib==3.7.2 tensorflow-privacy==0.8.12 tensorflow-compression==2.14.1 tensorflow-text==2.20.0 tensorflow_decision_forests==1.12.0 --no-deps

# Install torch and related packages
!pip install --no-cache-dir torch==2.6.0+cu124 torchao==0.10.0 torchaudio==2.6.0+cu124 torchdata==0.11.0 torchsummary==1.5.1 torchtune==0.6.1 torchvision==0.21.0+cu124 --index-url https://download.pytorch.org/whl/cu124

print("\n--- Installation Complete ---")
print("MANUAL RUNTIME RESTART REQUIRED: Click 'Runtime > Restart runtime' now, then run the verification cell.")

# Enable verbose TensorFlow logging
!export TF_CPP_MIN_LOG_LEVEL=0

print("\n--- Step 3: Try tf-nightly 2.20.0.dev20250514 ---")

# Check TensorFlow version and cuDNN status
!python -c "import tensorflow as tf; print('TensorFlow version:', tf.__version__); print('GPU Devices:', tf.config.list_physical_devices('GPU')); print('CUDA Built:', tf.test.is_built_with_cuda()); print('cuDNN Built:', hasattr(tf.test, 'is_built_with_cudnn') and tf.test.is_built_with_cudnn()); print('CUDA Version:', tf.sysconfig.get_build_info().get('cuda_version', 'Not found')); print('cuDNN Version:', tf.sysconfig.get_build_info().get('cudnn_version', 'Not found'))" || echo "TensorFlow import failed"

# Check TensorFlow shared libraries
print("\n--- TensorFlow Shared Libraries ---")
!find /usr/local/lib/python3.11/dist-packages/tensorflow -name "*.so" 2>/dev/null || echo "No shared libraries found"

# Check TensorFlow library dependencies
print("\n--- TensorFlow Library Dependencies ---")
!find /usr/local/lib/python3.11/dist-packages/tensorflow -name "*.so" -exec ldd {} \; | grep cudnn 2>/dev/null || echo "No cuDNN dependency found"

# Check cuDNN libraries
print("\n--- cuDNN Library Check ---")
!ls -l /lib/x86_64-linux-gnu | grep cudnn 2>/dev/null || echo "cuDNN not found"
!ldconfig -p | grep -E 'libcudnn'

# Check environment variables
print("\n--- Environment Variables ---")
!echo $CUDA_HOME
!echo $LD_LIBRARY_PATH
!echo $PATH
!cat /etc/environment

# Check installed packages
print("\n--- Installed Packages ---")
!pip list | grep -E 'nvidia|tensorflow|tf-nightly|numpy|scipy|appfl|protobuf|ml-dtypes|torch'

# Test SciPy import
print("\n--- SciPy Test ---")
!python -c "import scipy; print('SciPy version:', scipy.__version__)" || echo "SciPy import failed"

!nvidia-smi

print("\n--- Step 3 Complete ---")
print("Check 'cuDNN Built', 'TensorFlow Library Dependencies', and 'cuDNN Library Check'.")

# Colab cell: check GPU
!nvidia-smi

# Colab cell: enable mixed precision
import tensorflow as tf
from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy('mixed_float16')

print("Mixed precision policy:", mixed_precision.global_policy())

import random
import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
from IPython.display import clear_output
import gc

class Config:
    def __init__(self):
        pass

cfg = Config()
cfg.num_rounds = 100
cfg.clients_per_round = 8
cfg.learning_rate = 0.001
cfg.batch_size = 32
cfg.client_epochs = 4
cfg.num_clients = 10
cfg.examples_per_client = 2000
cfg.test_samples = 5000
cfg.optimizer = 'adam'
cfg.model_name = 'high_acc_cnn'
cfg.dataset = 'cifar10'

def advanced_preprocess(image, label, training=True):
    image = tf.cast(image, tf.float32) / 255.0
    if training:
        image = tf.image.random_flip_left_right(image)
        image = tf.image.random_brightness(image, 0.1)
        image = tf.image.random_contrast(image, 0.9, 1.1)
    return image, label

def get_data():
    test_ds = tfds.load('cifar10', split=f'test[:{cfg.test_samples}]', as_supervised=True)
    test_ds = test_ds.map(lambda x, y: advanced_preprocess(x, y, False),
                          num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_ds.batch(cfg.batch_size).cache().prefetch(tf.data.AUTOTUNE)

    client_datasets = {}
    client_val_datasets = {}

    for i in range(cfg.num_clients):
        client_split = f'train[{i*cfg.examples_per_client}:{(i+1)*cfg.examples_per_client}]'
        client_data = tfds.load('cifar10', split=client_split, as_supervised=True)

        total_examples = cfg.examples_per_client
        train_size = int(0.8 * total_examples)
        train_data = client_data.take(train_size)
        val_data = client_data.skip(train_size)

        train_data = train_data.map(lambda x, y: advanced_preprocess(x, y, True),
                                    num_parallel_calls=tf.data.AUTOTUNE)
        train_data = train_data.cache().shuffle(10000).batch(cfg.batch_size).prefetch(tf.data.AUTOTUNE)

        val_data = val_data.map(lambda x, y: advanced_preprocess(x, y, False),
                                num_parallel_calls=tf.data.AUTOTUNE)
        val_data = val_data.cache().batch(cfg.batch_size).prefetch(tf.data.AUTOTUNE)

        client_datasets[i] = train_data
        client_val_datasets[i] = val_data

    return client_datasets, client_val_datasets, test_ds

def create_high_acc_model():
    def conv_block(x, filters, kernel_size=3, strides=1):
        x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        return x

    def residual_block(x, filters):
        shortcut = x
        x = conv_block(x, filters)
        x = conv_block(x, filters)
        if shortcut.shape[-1] != filters:
            shortcut = conv_block(shortcut, filters, kernel_size=1)
        x = tf.keras.layers.Add()([shortcut, x])
        return tf.keras.layers.Activation('relu')(x)

    inputs = tf.keras.Input(shape=(32, 32, 3))
    x = conv_block(inputs, 64, strides=1)
    x = residual_block(x, 64)
    x = residual_block(x, 64)
    x = tf.keras.layers.MaxPooling2D(2)(x)
    x = tf.keras.layers.Dropout(0.2)(x)

    x = residual_block(x, 128)
    x = residual_block(x, 128)
    x = tf.keras.layers.MaxPooling2D(2)(x)
    x = tf.keras.layers.Dropout(0.3)(x)

    x = residual_block(x, 256)
    x = residual_block(x, 256)
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dropout(0.5)(x)

    x = tf.keras.layers.Dense(512, activation='relu')(x)
    x = tf.keras.layers.Dropout(0.5)(x)
    outputs = tf.keras.layers.Dense(10, activation='softmax', dtype='float32')(x)  # ensure output is float32

    model = tf.keras.Model(inputs, outputs)

    optimizer = tf.keras.optimizers.Adam(
        learning_rate=cfg.learning_rate,
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-7,
        amsgrad=True
    )

    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

def cosine_decay_with_warmup(epoch):
    warmup_epochs = 5
    if epoch < warmup_epochs:
        return cfg.learning_rate * ((epoch + 1) / warmup_epochs)
    decay_epochs = cfg.num_rounds - warmup_epochs
    epoch = epoch - warmup_epochs
    cosine_decay = 0.5 * (1 + np.cos(np.pi * epoch / decay_epochs))
    alpha = 0.1
    return cfg.learning_rate * (alpha + (1 - alpha) * cosine_decay)

def federated_learning():
    print("Starting federated learning on GPU...")
    client_data, client_val_data, test_data = get_data()
    global_model = create_high_acc_model()
    test_accuracies = []

    best_accuracy = 0.0
    best_weights = None
    patience = 20
    no_improvement_rounds = 0

    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(cosine_decay_with_warmup)

    client_model = create_high_acc_model()

    for round_num in range(cfg.num_rounds):
        print(f"\nRound {round_num+1}/{cfg.num_rounds}")

        if round_num > 0:
            client_scores = []
            for client_id in range(cfg.num_clients):
                val_loss, val_acc = global_model.evaluate(client_val_data[client_id], verbose=0)
                client_scores.append((client_id, val_acc))

            client_scores.sort(key=lambda x: x[1], reverse=True)
            selected = [x[0] for x in client_scores[:cfg.clients_per_round//2]]
            remaining = [x[0] for x in client_scores[cfg.clients_per_round//2:]]
            selected.extend(random.sample(remaining, cfg.clients_per_round//2))
        else:
            selected = random.sample(range(cfg.num_clients), cfg.clients_per_round)

        client_weights = []

        for client_id in selected:
            print(f"Training client {client_id}...", end=" ")
            client_model.set_weights(global_model.get_weights())

            client_model.fit(
                client_data[client_id],
                epochs=cfg.client_epochs,
                verbose=0,
                callbacks=[lr_scheduler]
            )

            val_loss, val_acc = client_model.evaluate(client_val_data[client_id], verbose=0)
            print(f"Val Acc: {val_acc:.3f}")
            client_weights.append(client_model.get_weights())

        if client_weights:
            avg_weights = []
            for weights_list_tuple in zip(*client_weights):
                avg_weights.append(np.mean(weights_list_tuple, axis=0))

            global_model.set_weights(avg_weights)
            loss, acc = global_model.evaluate(test_data, verbose=0)
            test_accuracies.append(acc)

            print(f"Round {round_num+1} Test Accuracy: {acc:.4f}")

            if acc > best_accuracy:
                best_accuracy = acc
                best_weights = global_model.get_weights()
                no_improvement_rounds = 0
                print(f"New best: {best_accuracy:.4f}")
            else:
                no_improvement_rounds += 1

            if no_improvement_rounds >= patience:
                print(f"Early stopping: No improvement for {patience} rounds")
                break

            if acc >= 0.95:
                print(f"🎯 Target accuracy of 95% reached! Final: {acc:.4f}")
                break

    if best_weights is not None:
        global_model.set_weights(best_weights)
        final_loss, final_acc = global_model.evaluate(test_data, verbose=0)
        print(f"Best model restored with accuracy: {final_acc:.4f}")
        # Save the best model in the SavedModel format
        global_model.export('best_federated_model') # Changed from save to export
        print("✅ Model saved as 'best_federated_model'")
    else:
        final_loss, final_acc = global_model.evaluate(test_data, verbose=0)
        # If no best weights, save the final model
        global_model.export('best_federated_model') # Changed from save to export
        print("✅ Model saved as 'best_federated_model'")


    plt.figure(figsize=(10, 5))
    plt.plot(test_accuracies, marker='o')
    plt.axhline(y=0.95, color='r', linestyle='--', label='95% Target')
    plt.title('Test Accuracy Progression')
    plt.xlabel('Round')
    plt.ylabel('Accuracy')
    plt.grid(True)
    plt.legend()
    plt.show()

    return global_model, final_acc

if __name__ == "__main__":
    print("Starting federated learning on GPU (Tesla T4)...")
    model, final_acc = federated_learning()
    print(f"\nFinal Result: {final_acc:.4f}")

!zip -r best_federated_model.zip best_federated_model

from google.colab import files
files.download('best_federated_model.zip')